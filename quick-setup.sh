#!/bin/bash

# ðŸš€ AnythingLLM Quick Setup Script for Coolify
# Este script configura rÃ¡pidamente AnythingLLM para deployment en Coolify

echo "ðŸš€ Configurando AnythingLLM para Coolify..."

# Generar claves de seguridad Ãºnicas
echo "ðŸ” Generando claves de seguridad..."
JWT_SECRET=$(node -e "console.log(require('crypto').randomBytes(32).toString('hex'))")
SIG_KEY=$(node -e "console.log(require('crypto').randomBytes(32).toString('hex'))")
SIG_SALT=$(node -e "console.log(require('crypto').randomBytes(32).toString('hex'))")

# Crear archivo de configuraciÃ³n para Coolify
cat > .env.coolify << EOF
# ðŸ” Claves de seguridad generadas automÃ¡ticamente
JWT_SECRET=$JWT_SECRET
SIG_KEY=$SIG_KEY  
SIG_SALT=$SIG_SALT

# ðŸ“¦ ConfiguraciÃ³n bÃ¡sica
SERVER_PORT=3001
STORAGE_DIR=/app/server/storage
NODE_ENV=production
ANYTHING_LLM_RUNTIME=docker

# ðŸ›¡ï¸ Privacidad y seguridad
DISABLE_TELEMETRY=true

# ðŸ§  ConfiguraciÃ³n por defecto
EMBEDDING_ENGINE=native
VECTOR_DB=lancedb

# ðŸ¤– ConfiguraciÃ³n LLM (elige y descomenta uno)
# === OpenAI ===
# LLM_PROVIDER=openai
# OPEN_AI_KEY=sk-tu-clave-openai-aqui
# OPEN_MODEL_PREF=gpt-4o

# === Ollama (modelos locales) ===
# LLM_PROVIDER=ollama  
# OLLAMA_BASE_PATH=http://host.docker.internal:11434
# OLLAMA_MODEL_PREF=llama3.2:latest

# === Azure OpenAI ===
# LLM_PROVIDER=azure
# AZURE_OPENAI_ENDPOINT=https://tu-recurso.openai.azure.com
# AZURE_OPENAI_KEY=tu-clave-azure
# AZURE_OPENAI_MODEL_PREF=gpt-4

# === Google Gemini ===
# LLM_PROVIDER=gemini
# GEMINI_API_KEY=tu-clave-gemini  
# GEMINI_LLM_MODEL_PREF=gemini-2.0-flash-lite

# === Anthropic Claude ===
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=tu-clave-anthropic
# ANTHROPIC_MODEL_PREF=claude-3-sonnet-20240229
EOF

echo "âœ… Archivo .env.coolify creado con claves seguras"

# Mostrar resumen
echo ""
echo "ðŸ“‹ RESUMEN DE CONFIGURACIÃ“N:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ðŸ” JWT_SECRET: $JWT_SECRET"
echo "ðŸ” SIG_KEY: $SIG_KEY"
echo "ðŸ” SIG_SALT: $SIG_SALT"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

echo "ðŸš€ PRÃ“XIMOS PASOS:"
echo "1. Copia el contenido de .env.coolify en las variables de entorno de Coolify"
echo "2. Configura tu proveedor LLM preferido"
echo "3. Usa docker-compose.coolify.yml para el deployment"
echo "4. Â¡Deploy y disfruta!"
echo ""

echo "ðŸ“š Archivos importantes creados:"
echo "â€¢ docker-compose.coolify.yml - ConfiguraciÃ³n Docker para Coolify"
echo "â€¢ .env.coolify - Variables de entorno con claves seguras"
echo "â€¢ COOLIFY_DEPLOYMENT.md - GuÃ­a completa de deployment"
echo "â€¢ GENERATED_KEYS.md - DocumentaciÃ³n de las claves"
echo ""

echo "âœ… Â¡AnythingLLM listo para Coolify!"